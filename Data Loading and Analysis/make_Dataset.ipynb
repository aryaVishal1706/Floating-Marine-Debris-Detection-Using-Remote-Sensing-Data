{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b10cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "from rasterio.plot import reshape_as_image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dropout, concatenate, Conv2DTranspose\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.metrics import MeanIoU\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2c0f7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading training data: 100%|███████████████| 694/694 [00:00<00:00, 68746.09it/s]\n",
      "Loading validation data: 100%|████████████| 328/328 [00:00<00:00, 105186.31it/s]\n",
      "Loading testing data: 100%|███████████████| 359/359 [00:00<00:00, 107862.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training samples: 694\n",
      "Number of validation samples: 328\n",
      "Number of testing samples: 359\n",
      "\n",
      "Example paths:\n",
      "Training example: ('MARIDA/patches/S2_12-1-17_16PCC/S2_12-1-17_16PCC_19.tif', 'MARIDA/patches/S2_12-1-17_16PCC/S2_12-1-17_16PCC_19_cl.tif')\n",
      "Validation example: ('MARIDA/patches/S2_11-6-18_16PCC/S2_11-6-18_16PCC_0.tif', 'MARIDA/patches/S2_11-6-18_16PCC/S2_11-6-18_16PCC_0_cl.tif')\n",
      "Testing example: ('MARIDA/patches/S2_12-12-20_16PCC/S2_12-12-20_16PCC_0.tif', 'MARIDA/patches/S2_12-12-20_16PCC/S2_12-12-20_16PCC_0_cl.tif')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_dataset(dataset_path, split_path):\n",
    "    \"\"\"\n",
    "    Load dataset for pixel-based binary classification.\n",
    "\n",
    "    Parameters:\n",
    "    - dataset_path (str): Path to the main dataset folder.\n",
    "    - split_path (str): Path to the folder containing train_X.txt, val_X.txt, and test_X.txt.\n",
    "\n",
    "    Returns:\n",
    "    - train_data (list): List of tuples (image_path, mask_path) for training.\n",
    "    - val_data (list): List of tuples (image_path, mask_path) for validation.\n",
    "    - test_data (list): List of tuples (image_path, mask_path) for testing.\n",
    "    \"\"\"\n",
    "\n",
    "    # Paths to splits\n",
    "    train_split_file = os.path.join(split_path, 'train_X.txt')\n",
    "    val_split_file = os.path.join(split_path, 'val_X.txt')\n",
    "    test_split_file = os.path.join(split_path, 'test_X.txt')\n",
    "\n",
    "    # Read splits from text files\n",
    "    with open(train_split_file, 'r') as f:\n",
    "        train_images = [line.strip() for line in f.readlines()]\n",
    "    with open(val_split_file, 'r') as f:\n",
    "        val_images = [line.strip() for line in f.readlines()]\n",
    "    with open(test_split_file, 'r') as f:\n",
    "        test_images = [line.strip() for line in f.readlines()]\n",
    "\n",
    "    # Initialize lists to store data\n",
    "    train_data = []\n",
    "    val_data = []\n",
    "    test_data = []\n",
    "\n",
    "    # Function to get image and mask paths\n",
    "    def get_paths(image_name):\n",
    "        if(image_name[-3] == '_'):\n",
    "            image_folder = os.path.join(dataset_path, 'patches', f'S2_{image_name[:-3]}')\n",
    "        else:\n",
    "            image_folder = os.path.join(dataset_path, 'patches', f'S2_{image_name[:-2]}')\n",
    "        # Main image path\n",
    "        image_path = os.path.join(image_folder, f'S2_{image_name}.tif')\n",
    "\n",
    "        # Mask path\n",
    "        mask_path = os.path.join(image_folder, f'S2_{image_name}_cl.tif')\n",
    "\n",
    "        return image_path, mask_path\n",
    "\n",
    "\n",
    "    # Collect data for training set\n",
    "    for image_name in tqdm(train_images, desc='Loading training data'):\n",
    "        image_path, mask_path = get_paths(image_name)\n",
    "        train_data.append((image_path, mask_path))\n",
    "\n",
    "    # Collect data for validation set\n",
    "    for image_name in tqdm(val_images, desc='Loading validation data'):\n",
    "        image_path, mask_path = get_paths(image_name)\n",
    "        val_data.append((image_path, mask_path))\n",
    "\n",
    "    # Collect data for test set\n",
    "    for image_name in tqdm(test_images, desc='Loading testing data'):\n",
    "        image_path, mask_path = get_paths(image_name)\n",
    "        test_data.append((image_path, mask_path))\n",
    "\n",
    "    return train_data, val_data, test_data\n",
    "\n",
    "# Example usage:\n",
    "dataset_path = 'MARIDA'  # Replace with your actual path to the main dataset folder\n",
    "split_path = os.path.join(dataset_path, 'splits')\n",
    "\n",
    "train_data, val_data, test_data = load_dataset(dataset_path, split_path)\n",
    "\n",
    "# Example of how to access the data\n",
    "print(f\"Number of training samples: {len(train_data)}\")\n",
    "print(f\"Number of validation samples: {len(val_data)}\")\n",
    "print(f\"Number of testing samples: {len(test_data)}\")\n",
    "print(\"\\nExample paths:\")\n",
    "print(\"Training example:\", train_data[20])\n",
    "print(\"Validation example:\", val_data[0])\n",
    "print(\"Testing example:\", test_data[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f7cf9790",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('MARIDA\\\\patches\\\\1-12-19_48MYU_1\\\\1-12-19_48MYU_1_0.tif',\n",
       " 'MARIDA\\\\patches\\\\1-12-19_48MYU_1\\\\1-12-19_48MYU_1_cl.tif')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "57a50446-0b91-4ca7-8a1e-7eeae3f43eef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n",
      "sjslk\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "def upload_images(train, folder_name):\n",
    "    # Create the target folder if it doesn't exist\n",
    "    if not os.path.exists(folder_name):\n",
    "        os.makedirs(folder_name)\n",
    "    \n",
    "    # Iterate through each image path in train and copy it to the folder\n",
    "    for image_tuple in train:\n",
    "        try:\n",
    "            # Extract the filenames from the tuple\n",
    "            image_path = image_tuple[0]\n",
    "            # cl_path = image_tuple[1]\n",
    "            \n",
    "            # Extract the filenames from the paths\n",
    "            image_filename = os.path.basename(image_path)\n",
    "            # cl_filename = os.path.basename(cl_path)\n",
    "            \n",
    "            # Copy the image and its associated file to the target folder\n",
    "            shutil.copy(image_path, os.path.join(folder_name, image_filename))\n",
    "            # shutil.copy(cl_path, os.path.join(folder_name, cl_filename))\n",
    "            print(\"sjslk\")\n",
    "            # print(f\"Uploaded {image_filename} and {cl_filename} to {folder_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error uploading {image_path}: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "folder_name = 'MARIDA/test/input'\n",
    "\n",
    "upload_images(test_data, folder_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6db02db-4117-4696-896a-2cd9e881f379",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
